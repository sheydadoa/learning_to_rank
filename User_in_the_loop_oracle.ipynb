{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896c8380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from graspologic.embed import AdjacencySpectralEmbed as ASE\n",
    "from graspologic.embed import LaplacianSpectralEmbed as LSE\n",
    "from graspologic.simulations import rdpg\n",
    "from graspologic.simulations import mmsbm\n",
    "from graspologic.plot import pairplot\n",
    "from graspologic.plot import heatmap\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import combining_representations.combining_representations as cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d12c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation and contributors.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "import warnings\n",
    "from typing import Any, Callable, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import check_array, check_scalar\n",
    "\n",
    "from graspologic.types import Dict, List, Tuple\n",
    "from graspologic.utils import cartesian_product, symmetrize\n",
    "# from ..utils import cartesian_product, symmetrize\n",
    "\n",
    "\n",
    "def _n_to_labels(n: np.ndarray) -> np.ndarray:\n",
    "    n_cumsum = n.cumsum()\n",
    "    labels = np.zeros(n.sum(), dtype=np.int64)\n",
    "    for i in range(1, len(n)):\n",
    "        labels[n_cumsum[i - 1] : n_cumsum[i]] = i\n",
    "    return labels\n",
    "\n",
    "\n",
    "def sample_edges(\n",
    "    P: np.ndarray, directed: bool = False, loops: bool = False\n",
    ") -> np.ndarray:\n",
    " \n",
    "    if type(P) is not np.ndarray:\n",
    "        raise TypeError(\"P must be numpy.ndarray\")\n",
    "    if len(P.shape) != 2:\n",
    "        raise ValueError(\"P must have dimension 2 (n_vertices, n_dimensions)\")\n",
    "    if P.shape[0] != P.shape[1]:\n",
    "        raise ValueError(\"P must be a square matrix\")\n",
    "    if not directed:\n",
    "        # can cut down on sampling by ~half\n",
    "        triu_inds = np.triu_indices(P.shape[0])\n",
    "        samples = np.random.binomial(1, P[triu_inds])\n",
    "        A = np.zeros_like(P)\n",
    "        A[triu_inds] = samples\n",
    "        A = symmetrize(A, method=\"triu\")\n",
    "    else:\n",
    "        A = np.random.binomial(1, P)\n",
    "\n",
    "    if loops:\n",
    "        return A\n",
    "    else:\n",
    "        return A - np.diag(np.diag(A))\n",
    "\n",
    "\n",
    "def er_np(\n",
    "    n: int,\n",
    "    p: float,\n",
    "    directed: bool = False,\n",
    "    loops: bool = False,\n",
    "    wt: Union[int, np.ndarray, List[int]] = 1,\n",
    "    wtargs: Optional[Dict[str, Any]] = None,\n",
    "    dc: Optional[Union[Callable, np.ndarray]] = None,\n",
    "    dc_kws: Dict[str, Any] = {},\n",
    ") -> np.ndarray:\n",
    "   \n",
    "    if isinstance(dc, (list, np.ndarray)) and all(callable(f) for f in dc):\n",
    "        raise TypeError(\"dc is not of type function or array-like of scalars\")\n",
    "    if not np.issubdtype(type(n), np.integer):\n",
    "        raise TypeError(\"n is not of type int.\")\n",
    "    if not np.issubdtype(type(p), np.floating):\n",
    "        raise TypeError(\"p is not of type float.\")\n",
    "    if type(loops) is not bool:\n",
    "        raise TypeError(\"loops is not of type bool.\")\n",
    "    if type(directed) is not bool:\n",
    "        raise TypeError(\"directed is not of type bool.\")\n",
    "    n_sbm = np.array([n])\n",
    "    p_sbm = np.array([[p]])\n",
    "    g = sbm(n_sbm, p_sbm, directed, loops, wt, wtargs, dc, dc_kws)\n",
    "    return g  # type: ignore\n",
    "\n",
    "\n",
    "\n",
    "def er_nm(\n",
    "    n: int,\n",
    "    m: int,\n",
    "    directed: bool = False,\n",
    "    loops: bool = False,\n",
    "    wt: Union[int, np.ndarray, List[int]] = 1,\n",
    "    wtargs: Optional[Dict[str, Any]] = None,\n",
    ") -> np.ndarray:\n",
    "    \n",
    "    if not np.issubdtype(type(m), np.integer):\n",
    "        raise TypeError(\"m is not of type int.\")\n",
    "    elif m <= 0:\n",
    "        msg = \"m must be > 0.\"\n",
    "        raise ValueError(msg)\n",
    "    if not np.issubdtype(type(n), np.integer):\n",
    "        raise TypeError(\"n is not of type int.\")\n",
    "    elif n <= 0:\n",
    "        msg = \"n must be > 0.\"\n",
    "        raise ValueError(msg)\n",
    "    if type(directed) is not bool:\n",
    "        raise TypeError(\"directed is not of type bool.\")\n",
    "    if type(loops) is not bool:\n",
    "        raise TypeError(\"loops is not of type bool.\")\n",
    "\n",
    "    # check weight function\n",
    "    if not np.issubdtype(type(wt), np.integer):\n",
    "        if not callable(wt):\n",
    "            raise TypeError(\"You have not passed a function for wt.\")\n",
    "\n",
    "    # compute max number of edges to sample\n",
    "    if loops:\n",
    "        if directed:\n",
    "            max_edges = n**2\n",
    "            msg = \"n^2\"\n",
    "        else:\n",
    "            max_edges = n * (n + 1) // 2\n",
    "            msg = \"n(n+1)/2\"\n",
    "    else:\n",
    "        if directed:\n",
    "            max_edges = n * (n - 1)\n",
    "            msg = \"n(n-1)\"\n",
    "        else:\n",
    "            max_edges = n * (n - 1) // 2\n",
    "            msg = \"n(n-1)/2\"\n",
    "    if m > max_edges:\n",
    "        msg = \"You have passed a number of edges, {}, exceeding {}, {}.\"\n",
    "        msg = msg.format(m, msg, max_edges)\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    A = np.zeros((n, n))\n",
    "    # check if directedness is desired\n",
    "    if directed:\n",
    "        if loops:\n",
    "            # use all of the indices\n",
    "            idx = np.where(np.logical_not(A))\n",
    "        else:\n",
    "            # use only the off-diagonal indices\n",
    "            idx = np.where(~np.eye(n, dtype=bool))\n",
    "    else:\n",
    "        # use upper-triangle indices, and ignore diagonal according\n",
    "        # to loops argument\n",
    "        idx = np.triu_indices(n, k=int(loops is False))\n",
    "\n",
    "    # get idx in 1d coordinates by ravelling\n",
    "    triu = np.ravel_multi_index(idx, A.shape)\n",
    "    # choose M of them\n",
    "    triu = np.random.choice(triu, size=m, replace=False)\n",
    "    # unravel back\n",
    "    triu = np.unravel_index(triu, A.shape)\n",
    "    # check weight function\n",
    "    if callable(wt):\n",
    "        wt = wt(size=m, **wtargs)\n",
    "    A[triu] = wt\n",
    "\n",
    "    if not directed:\n",
    "        A = symmetrize(A, method=\"triu\")\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "def sbm(\n",
    "    n: Union[np.ndarray, List[int]],\n",
    "    p: np.ndarray,\n",
    "    directed: bool = False,\n",
    "    loops: bool = False,\n",
    "    wt: Union[int, np.ndarray, List[int]] = 1,\n",
    "    wtargs: Optional[Union[np.ndarray, Dict[str, Any]]] = None,\n",
    "    dc: Optional[Union[Callable, np.ndarray]] = None,\n",
    "    dc_kws: Union[Dict[str, Any], List[Dict[str, Any]], np.ndarray] = {},\n",
    "    return_labels: bool = False,\n",
    ") -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n",
    "   \n",
    "    # Check n\n",
    "    if not isinstance(n, (list, np.ndarray)):\n",
    "        msg = \"n must be a list or np.array, not {}.\".format(type(n))\n",
    "        raise TypeError(msg)\n",
    "    else:\n",
    "        n = np.array(n)\n",
    "        if not np.issubdtype(n.dtype, np.integer):\n",
    "            msg = \"There are non-integer elements in n\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "    # Check p\n",
    "    if not isinstance(p, (list, np.ndarray)):\n",
    "        msg = \"p must be a list or np.array, not {}.\".format(type(p))\n",
    "        raise TypeError(msg)\n",
    "    else:\n",
    "        p = np.array(p)\n",
    "        if not np.issubdtype(p.dtype, np.number):\n",
    "            msg = \"There are non-numeric elements in p\"\n",
    "            raise ValueError(msg)\n",
    "        elif p.shape != (n.size, n.size):\n",
    "            msg = \"p must have shape len(n) x len(n), not {}\".format(p.shape)\n",
    "            raise ValueError(msg)\n",
    "        elif np.any(p < 0) or np.any(p > 1):\n",
    "            msg = \"Values in p must be in between 0 and 1.\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "    # Check wt and wtargs\n",
    "    if not np.issubdtype(type(wt), np.number) and not callable(wt):\n",
    "        if not isinstance(wt, (list, np.ndarray)):\n",
    "            msg = \"wt must be a numeric, list, or np.array, not {}\".format(type(wt))\n",
    "            raise TypeError(msg)\n",
    "        if not isinstance(wtargs, (list, np.ndarray)):\n",
    "            msg = \"wtargs must be a numeric, list, or np.array, not {}\".format(\n",
    "                type(wtargs)\n",
    "            )\n",
    "            raise TypeError(msg)\n",
    "\n",
    "        wt = np.array(wt, dtype=object)\n",
    "        wtargs = np.array(wtargs, dtype=object)\n",
    "        # if not number, check dimensions\n",
    "        if wt.shape != (n.size, n.size):\n",
    "            msg = \"wt must have size len(n) x len(n), not {}\".format(wt.shape)\n",
    "            raise ValueError(msg)\n",
    "        if wtargs.shape != (n.size, n.size):\n",
    "            msg = \"wtargs must have size len(n) x len(n), not {}\".format(wtargs.shape)\n",
    "            raise ValueError(msg)\n",
    "        # check if each element is a function\n",
    "        for element in wt.ravel():\n",
    "            if not callable(element):\n",
    "                msg = \"{} is not a callable function.\".format(element)\n",
    "                raise TypeError(msg)\n",
    "    else:\n",
    "        wt = np.full(p.shape, wt, dtype=object)\n",
    "        wtargs = np.full(p.shape, wtargs, dtype=object)\n",
    "\n",
    "    # Check directed\n",
    "    if not directed:\n",
    "        if np.any(p != p.T):\n",
    "            raise ValueError(\"Specified undirected, but P is directed.\")\n",
    "        if np.any(wt != wt.T):\n",
    "            raise ValueError(\"Specified undirected, but Wt is directed.\")\n",
    "        if np.any(wtargs != wtargs.T):\n",
    "            raise ValueError(\"Specified undirected, but Wtargs is directed.\")\n",
    "\n",
    "    K = len(n)  # the number of communities\n",
    "    counter = 0\n",
    "    # get a list of community indices\n",
    "    cmties = []\n",
    "    for i in range(0, K):\n",
    "        cmties.append(range(counter, counter + n[i]))\n",
    "        counter += n[i]\n",
    "\n",
    "    # Check degree-corrected input parameters\n",
    "    if callable(dc):\n",
    "        # Check that the paramters are a dict\n",
    "        if not isinstance(dc_kws, dict):\n",
    "            msg = \"dc_kws must be of type dict not{}\".format(type(dc_kws))\n",
    "            raise TypeError(msg)\n",
    "        # Create the probability matrix for each vertex\n",
    "        dcProbs = np.array([dc(**dc_kws) for _ in range(0, sum(n))], dtype=\"float\")\n",
    "        for indices in cmties:\n",
    "            dcProbs[indices] /= sum(dcProbs[indices])\n",
    "    elif isinstance(dc, (list, np.ndarray)) and np.issubdtype(\n",
    "        np.array(dc).dtype, np.number\n",
    "    ):\n",
    "        dcProbs = np.array(dc, dtype=float)\n",
    "        # Check size and element types\n",
    "        if not np.issubdtype(dcProbs.dtype, np.number):\n",
    "            msg = \"There are non-numeric elements in dc, {}\".format(dcProbs.dtype)\n",
    "            raise ValueError(msg)\n",
    "        elif dcProbs.shape != (sum(n),):\n",
    "            msg = \"dc must have size equal to the number of\"\n",
    "            msg += \" vertices {0}, not {1}\".format(sum(n), dcProbs.shape)\n",
    "            raise ValueError(msg)\n",
    "        elif np.any(dcProbs < 0):\n",
    "            msg = \"Values in dc cannot be negative.\"\n",
    "            raise ValueError(msg)\n",
    "        # Check that probabilities sum to 1 in each block\n",
    "        for i in range(0, K):\n",
    "            if not np.isclose(sum(dcProbs[cmties[i]]), 1, atol=1.0e-8):\n",
    "                msg = \"Block {} probabilities should sum to 1, normalizing...\".format(i)\n",
    "                warnings.warn(msg, UserWarning)\n",
    "                dcProbs[cmties[i]] /= sum(dcProbs[cmties[i]])\n",
    "    elif isinstance(dc, (list, np.ndarray)) and all(callable(f) for f in dc):\n",
    "        dcFuncs = np.array(dc)\n",
    "        if dcFuncs.shape != (len(n),):\n",
    "            msg = \"dc must have size equal to the number of blocks {0}, not {1}\".format(\n",
    "                len(n), dcFuncs.shape\n",
    "            )\n",
    "            raise ValueError(msg)\n",
    "        # Check that the parameters type, length, and type\n",
    "        if not isinstance(dc_kws, (list, np.ndarray)):\n",
    "            # Allows for nonspecification of default parameters for all functions\n",
    "            if dc_kws == {}:\n",
    "                dc_kws = [{} for _ in range(0, len(n))]\n",
    "            else:\n",
    "                msg = \"dc_kws must be of type list or np.ndarray, not {}\".format(\n",
    "                    type(dc_kws)\n",
    "                )\n",
    "                raise TypeError(msg)\n",
    "        elif not len(dc_kws) == len(n):\n",
    "            msg = \"dc_kws must have size equal to\"\n",
    "            msg += \" the number of blocks {0}, not {1}\".format(len(n), len(dc_kws))\n",
    "            raise ValueError(msg)\n",
    "        elif not all(type(kw) == dict for kw in dc_kws):\n",
    "            msg = \"dc_kws elements must all be of type dict\"\n",
    "            raise TypeError(msg)\n",
    "        # Create the probability matrix for each vertex\n",
    "        dcProbs = np.array(\n",
    "            [\n",
    "                dcFunc(**kws)\n",
    "                for dcFunc, kws, size in zip(dcFuncs, dc_kws, n)\n",
    "                for _ in range(0, size)\n",
    "            ],\n",
    "            dtype=\"float\",\n",
    "        )\n",
    "        # dcProbs = dcProbs.astype(float)\n",
    "        for indices in cmties:\n",
    "            dcProbs[indices] /= sum(dcProbs[indices])\n",
    "            # dcProbs[indices] = dcProbs / dcProbs[indices].sum()\n",
    "    elif dc is not None:\n",
    "        msg = \"dc must be a function or a list or np.array of numbers or callable\"\n",
    "        msg += \" functions, not {}\".format(type(dc))\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # End Checks, begin simulation\n",
    "    A = np.zeros((sum(n), sum(n)))\n",
    "\n",
    "    for i in range(0, K):\n",
    "        if directed:\n",
    "            jrange = range(0, K)\n",
    "        else:\n",
    "            jrange = range(i, K)\n",
    "        for j in jrange:\n",
    "            block_wt = wt[i, j]\n",
    "            block_wtargs = wtargs[i, j]\n",
    "            block_p = p[i, j]\n",
    "            # identify submatrix for community i, j\n",
    "            # cartesian product to identify edges for community i,j pair\n",
    "            cprod = cartesian_product(cmties[i], cmties[j])  # type: ignore\n",
    "            # get idx in 1d coordinates by ravelling\n",
    "            triu = np.ravel_multi_index((cprod[:, 0], cprod[:, 1]), A.shape)\n",
    "            pchoice = np.random.uniform(size=len(triu))\n",
    "            if dc is not None:\n",
    "                # (v1,v2) connected with probability p*k_i*k_j*dcP[v1]*dcP[v2]\n",
    "                num_edges = sum(pchoice < block_p)\n",
    "                edge_dist = dcProbs[cprod[:, 0]] * dcProbs[cprod[:, 1]]\n",
    "                # If n_edges greater than support of dc distribution, pick fewer edges\n",
    "                if num_edges > sum(edge_dist > 0):\n",
    "                    msg = \"More edges sampled than nonzero pairwise dc entries.\"\n",
    "                    msg += \" Picking fewer edges\"\n",
    "                    warnings.warn(msg, UserWarning)\n",
    "                    num_edges = sum(edge_dist > 0)\n",
    "                triu = np.random.choice(\n",
    "                    triu, size=num_edges, replace=False, p=edge_dist\n",
    "                )\n",
    "            else:\n",
    "                # connected with probability p\n",
    "                triu = triu[pchoice < block_p]\n",
    "            if type(block_wt) is not int:\n",
    "                block_wt = block_wt(size=len(triu), **block_wtargs)\n",
    "            triu = np.unravel_index(triu, A.shape)\n",
    "            A[triu] = block_wt\n",
    "\n",
    "    if not loops:\n",
    "        A = A - np.diag(np.diag(A))\n",
    "    if not directed:\n",
    "        A = symmetrize(A, method=\"triu\")\n",
    "    if return_labels:\n",
    "        labels = _n_to_labels(n)\n",
    "        return A, labels\n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "def rdpg(\n",
    "    X: np.ndarray,\n",
    "    Y: Optional[np.ndarray] = None,\n",
    "    rescale: bool = False,\n",
    "    directed: bool = False,\n",
    "    loops: bool = False,\n",
    "    wt: Optional[Union[int, float, Callable]] = 1,\n",
    "    wtargs: Optional[Dict[str, Any]] = None,\n",
    ") -> np.ndarray:\n",
    "    \n",
    "    P = p_from_latent(X, Y, rescale=rescale, loops=loops)\n",
    "    A = sample_edges(P, directed=directed, loops=loops)\n",
    "\n",
    "    # check weight function\n",
    "    if (not np.issubdtype(type(wt), np.integer)) and (\n",
    "        not np.issubdtype(type(wt), np.floating)\n",
    "    ):\n",
    "        if not callable(wt):\n",
    "            raise TypeError(\"You have not passed a function for wt.\")\n",
    "\n",
    "    if callable(wt):\n",
    "        if wtargs is None:\n",
    "            wtargs = dict()\n",
    "        wts = wt(size=(np.count_nonzero(A)), **wtargs)\n",
    "        A[A > 0] = wts\n",
    "    else:\n",
    "        A *= wt  # type: ignore\n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "def p_from_latent(\n",
    "    X: np.ndarray,\n",
    "    Y: Optional[np.ndarray] = None,\n",
    "    rescale: bool = False,\n",
    "    loops: bool = True,\n",
    ") -> np.ndarray:\n",
    "   \n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    if type(X) is not np.ndarray or type(Y) is not np.ndarray:\n",
    "        raise TypeError(\"Latent positions must be numpy.ndarray\")\n",
    "    if X.ndim != 2 or Y.ndim != 2:\n",
    "        raise ValueError(\n",
    "            \"Latent positions must have dimension 2 (n_vertices, n_dimensions)\"\n",
    "        )\n",
    "    if X.shape != Y.shape:\n",
    "        raise ValueError(\"Dimensions of latent positions X and Y must be the same\")\n",
    "    P = X @ Y.T\n",
    "    # should this be before or after the rescaling, could give diff answers\n",
    "    if not loops:\n",
    "        P = P - np.diag(np.diag(P))\n",
    "    if rescale:\n",
    "        if P.min() < 0:\n",
    "            P = P - P.min()\n",
    "        if P.max() > 1:\n",
    "            P = P / P.max()\n",
    "    else:\n",
    "        P[P < 0] = 0\n",
    "        P[P > 1] = 1\n",
    "    return P\n",
    "\n",
    "\n",
    "def mmsbm(\n",
    "    n: int,\n",
    "    p: np.ndarray,\n",
    "    alpha: Optional[np.ndarray] = None,\n",
    "    rng: Optional[np.random.Generator] = None,\n",
    "    directed: bool = False,\n",
    "    loops: bool = False,\n",
    "    return_labels: bool = False,\n",
    ") -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n",
    "   \n",
    "    check_scalar(x=n, name=\"n\", target_type=int, min_val=1)\n",
    "\n",
    "    p = check_array(p, ensure_2d=True)\n",
    "    nx, ny = p.shape\n",
    "    if nx != ny:\n",
    "        msg = \"p must be a square matrix, not {}\".format(p.shape)\n",
    "        raise ValueError(msg)\n",
    "    if not np.issubdtype(p.dtype, np.number):\n",
    "        msg = \"There are non-numeric elements in p\"\n",
    "        raise ValueError(msg)\n",
    "    if np.any(p < 0) or np.any(p > 1):\n",
    "        msg = \"Values in p must be in between 0 and 1.\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    alpha_checked: np.ndarray\n",
    "    if alpha is None:\n",
    "        raise ValueError(\"alpha must not be None\")\n",
    "    else:\n",
    "        alpha_checked = alpha\n",
    "        alpha_checked = check_array(\n",
    "            alpha_checked, ensure_2d=False, ensure_min_features=1\n",
    "        )\n",
    "        if not np.issubdtype(alpha_checked.dtype, np.number):\n",
    "            msg = \"There are non-numeric elements in alpha\"\n",
    "            raise ValueError(msg)\n",
    "        if np.any(alpha_checked <= 0):\n",
    "            msg = \"Alpha entries must be > 0.\"\n",
    "            raise ValueError(msg)\n",
    "        if alpha_checked.shape != (len(p),):\n",
    "            msg = \"alpha must be a list or np.array of shape {c}, not {w}.\".format(\n",
    "                c=(len(p),), w=alpha_checked.shape\n",
    "            )\n",
    "            raise ValueError(msg)\n",
    "\n",
    "            \n",
    "    if rng == None:\n",
    "        rng = np.random.default_rng()\n",
    "    elif not isinstance(rng, np.random.Generator):\n",
    "        msg = \"rng must be <class 'numpy.random.Generator'> not {}.\".format(type(rng))\n",
    "        raise TypeError(msg)\n",
    "\n",
    "    if type(loops) is not bool:\n",
    "        raise TypeError(\"loops is not of type bool.\")\n",
    "    if type(directed) is not bool:\n",
    "        raise TypeError(\"directed is not of type bool.\")\n",
    "    if type(return_labels) is not bool:\n",
    "        raise TypeError(\"return_labels is not of type bool.\")\n",
    "\n",
    "    if not directed:\n",
    "        if np.any(p != p.T):\n",
    "            raise ValueError(\"Specified undirected, but P is directed.\")\n",
    "\n",
    "    # Naming convention follows paper listed in references.\n",
    "    mm_vectors = rng.dirichlet(alpha_checked, n)\n",
    "\n",
    "    mm_vectors = np.array(sorted(mm_vectors, key=lambda x: np.argmax(x)))\n",
    "\n",
    "    # labels:(n,n) matrix with all membership indicators for initiators and receivers\n",
    "    # instead of storing the indicator vector, argmax is directly computed\n",
    "    # check docstrings for more info.\n",
    "    labels = np.apply_along_axis(\n",
    "        lambda p_vector: np.argmax(\n",
    "            rng.multinomial(n=1, pvals=p_vector, size=n), axis=1\n",
    "        ),\n",
    "        axis=1,\n",
    "        arr=mm_vectors,\n",
    "    )\n",
    "\n",
    "    P = p[(labels, labels.T)]\n",
    "\n",
    "    A = sample_edges(P, directed=directed, loops=loops)\n",
    "\n",
    "    if not loops:\n",
    "        np.fill_diagonal(labels, -1)\n",
    "\n",
    "    if return_labels:\n",
    "        return (A, labels)\n",
    "\n",
    "    return A, mm_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f6b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_calc(inds,S_star,k):\n",
    "    count = 0\n",
    "    for ind in inds[:k]:\n",
    "        if ind in S_star:\n",
    "            count += 1\n",
    "    # precision at k\n",
    "    prec = count / k\n",
    "    return prec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e5b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dists_S(xhat, vstar, S, invert=False):\n",
    "    n,d = xhat.shape\n",
    "    dists_S = np.ones(n)\n",
    "\n",
    "    \n",
    "    if len(S) > 0:\n",
    "        dists_S[np.array(S)] = np.linalg.norm(xhat[vstar] - xhat[S], axis=1)\n",
    "        non_S = np.array([i for i in range(n) if i not in S and i!=vstar])\n",
    "\n",
    "        for ind in non_S:\n",
    "            temp_to_S = np.linalg.norm(xhat[ind] - xhat[S], axis=1)\n",
    "            argmin = S[np.argmin(temp_to_S)]\n",
    "            dists_S[ind] = np.linalg.norm(xhat[ind] - xhat[argmin])**2 + np.linalg.norm(xhat[argmin] - xhat[vstar])**2\n",
    "    \n",
    "    if invert:\n",
    "        dists_S = 1 / dists_S\n",
    "        \n",
    "    dists_S[vstar] = 0\n",
    "        \n",
    "    return dists_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1304e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_current_state(xhat, vstar, S_star, S, T):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    colors = sns.color_palette(\"Set1\",n_colors=4)\n",
    "    \n",
    "    ax.scatter(xhat[:, 0], xhat[:, 1], color='k', alpha=0.1)\n",
    "    \n",
    "    ax.scatter(xhat[vstar, 0], xhat[vstar, 1], color='r', marker='*', s=50)\n",
    "    ax.scatter(xhat[S_star, 0], xhat[S_star, 1], color='y')\n",
    "    ax.scatter(xhat[S, 0], xhat[S, 1], color='g')\n",
    "    \n",
    "    if len(T) > 0:\n",
    "        ax.scatter(xhat[T, 0], xhat[T, 1], color='k')\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde7edde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgraspologic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdjacencySpectralEmbed \u001b[38;5;28;01mas\u001b[39;00m ASE\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      5\u001b[0m rank_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;66;03m# nr of times you go through user_in_the_loop\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Nr. of vertices\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from graspologic.embed import AdjacencySpectralEmbed as ASE\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "rank_iters = 10 # nr of times you go through user_in_the_loop\n",
    "# Nr. of vertices\n",
    "n = 1000\n",
    "# Nr. of blocks\n",
    "K = 2\n",
    "# P\n",
    "p = [[0.7,0.2],[0.2,0.05]]\n",
    "# sbm.alpha\n",
    "sbm_alpha = [0.1]*2\n",
    "\n",
    "S_star_size = 20\n",
    "initial_S_size=3\n",
    "\n",
    "n_mc=1\n",
    "n_labelings=5\n",
    "n_labels_per=10\n",
    "k = 50\n",
    "\n",
    "precisions = np.zeros((n_mc, n_labelings+1, 2)) \n",
    "\n",
    "for i in range(n_mc): \n",
    "    # note: +1 because we have a base case before the user loop\n",
    "    # Generate instance of Mixed membership SBM\n",
    "    G = mmsbm(n,p,sbm_alpha)\n",
    "    \n",
    "    # Grab membership vectors\n",
    "    pi_vecs = G[1]\n",
    "\n",
    "    # Randomly select a node to be vstar\n",
    "    vstar = np.random.choice(n, 1)[0]\n",
    "    \n",
    "    # Calculate \"distance\" from vstar to other vertices says their block memberships\n",
    "    dists_to_vstar = np.linalg.norm(pi_vecs - pi_vecs[vstar], axis=1)\n",
    "        \n",
    "    # Define S_star to be the S_star_size closest nodes to vstar\n",
    "    S_star = np.argsort(dists_to_vstar)[1: 1 + S_star_size]\n",
    "    \n",
    "    # Define T_star to be everything else\n",
    "    T_star = [i for i in range(n) if i not in S_star and i != vstar]\n",
    "    \n",
    "    print('S star:', S_star)\n",
    "\n",
    "    xhat = ASE(n_components=2).fit_transform(G[0])\n",
    "    \n",
    "    for j in range(n_labelings+1):\n",
    "        if j == 0:\n",
    "            # Initial S set\n",
    "            S = list(np.random.choice(S_star, initial_S_size))\n",
    "\n",
    "            # Initial T set (empty)\n",
    "            T = []\n",
    "\n",
    "        else:\n",
    "            n_labeled = 0\n",
    "            c=0\n",
    "            while n_labeled < n_labels_per:\n",
    "                if ranks[c] not in np.concatenate([S_and_T, [vstar]]):\n",
    "                    if ranks[c] in S_star:\n",
    "                        S = np.concatenate([S, [ranks[c]]])\n",
    "                    else:\n",
    "                        T = np.concatenate([T, [ranks[c]]])\n",
    "                    n_labeled+=1                \n",
    "                c+=1\n",
    "                \n",
    "        print('voi:', vstar)\n",
    "        print('S:', S)\n",
    "        print('T:', T)\n",
    "        \n",
    "        S_and_T = np.concatenate([S, T]) \n",
    "        S = np.array(S).astype(int)\n",
    "        T = np.array(T).astype(int)\n",
    "             \n",
    "            \n",
    "        # get S and T distances\n",
    "        dists_S = get_dists_S(xhat, vstar, S)\n",
    "        dists_T = get_dists_S(xhat, vstar, T, invert=True)\n",
    "        dists_eucl = np.linalg.norm(xhat[vstar] - xhat, axis=1)\n",
    "\n",
    "        # create distance matrix\n",
    "        dist_matrices = np.vstack([dists_S, dists_T, dists_eucl])\n",
    "        dist_matrices = dist_matrices[np.newaxis].transpose((0,2,1))\n",
    "\n",
    "        # ilp\n",
    "        \n",
    "#         if len(T) > 0:\n",
    "        alphahat_ilp = cr.multiple_pairs(dist_matrices, {vstar: S}, {vstar: T}, variable_num_tol=None)\n",
    "        dist_ilp=np.average(dist_matrices[0], weights=alphahat_ilp, axis=1)\n",
    "        print(alphahat_ilp)\n",
    "#         else:\n",
    "#             dist_ilp = dists_S\n",
    "#             print(\"just using dists_S\")\n",
    "        \n",
    "        \n",
    "        ranks = np.argsort(dist_ilp)\n",
    "    \n",
    "        # Remove S and T indices        \n",
    "        precisions[i, j, 0] = precision_calc(np.argsort(dist_ilp)[1:], S_star, k)\n",
    "        precisions[i, j, 1] = precision_calc(np.argsort(np.linalg.norm(xhat[vstar] - xhat, axis=1))[1:], S_star, k)\n",
    "        \n",
    "        plot_current_state(xhat, vstar, S_star, S, T)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cae301b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([195, 442, 208, 157,  59, 242, 230, 256, 465,  36,  42, 396, 137,\n",
       "       388,  51, 104, 382, 309, 266, 145, 240, 427,  37,   8,  22, 115,\n",
       "        38, 303, 164, 129,  92,  32,  27, 336, 260, 249, 209, 225, 461,\n",
       "       363,  75,  65, 339, 264, 400, 191, 121, 251, 141, 245,  77, 475,\n",
       "       275,  28, 128,  95, 474, 448, 323, 346, 193, 295, 361, 341, 322,\n",
       "       238,  53, 478, 288, 135, 413, 466, 492, 213, 130, 456, 278, 397,\n",
       "       298, 132, 360, 185, 493, 247,  64, 459, 327, 273,  19,  52, 122,\n",
       "       182, 227,  68, 317, 228, 146, 237, 441,  48, 270, 179, 271, 326,\n",
       "       453,   0, 406, 390, 488, 252, 119, 482, 480,  39, 405, 312, 241,\n",
       "        71, 375, 150, 216, 236, 431, 490,  13,   5,  35, 162,  90, 171,\n",
       "       138,  16, 356, 332, 420, 444, 108, 325, 365,  33, 451, 310, 387,\n",
       "       173, 229,  12,  91, 111, 411,  98, 123, 378,  67, 268, 117, 359,\n",
       "       314, 331, 114, 467,  23, 159,  43,  93, 370, 165, 170, 376, 384,\n",
       "       460, 476, 235, 419, 269,  76, 307, 352, 197, 282, 358, 422,  41,\n",
       "       426, 491, 222, 497,  72, 211, 318,  24,  63, 198, 414, 255,  20,\n",
       "       300, 110,  94, 153, 126, 399, 425, 319, 304,  50, 101, 203,  21,\n",
       "        26, 435, 391, 364, 156, 447, 167, 404, 181, 254, 479, 283,  69,\n",
       "       473,   6, 136, 330,  74, 148, 486,  84, 450, 120, 133,  54, 201,\n",
       "       299,  61, 212,  78, 168,   9, 107, 280, 127, 118,  70, 200, 471,\n",
       "       398, 301, 296, 226, 373, 169, 250, 434, 355, 415, 103,   4, 116,\n",
       "       429, 160, 144, 439, 289,  89, 109, 285, 371, 113, 389, 353,  83,\n",
       "       430, 418, 176, 329, 293, 316, 105, 234, 408, 377, 351, 281, 276,\n",
       "       337, 342, 385, 199, 158, 140, 367, 218,  80,   3, 483, 416, 154,\n",
       "        62, 205, 219,  66, 265, 190, 210, 455, 166, 291, 421,  45, 313,\n",
       "       469, 402, 305, 487,  97,  82,  87, 131, 446, 328, 272,  60, 174,\n",
       "       324,  11, 440, 217, 214, 333, 163, 436, 274, 147, 290, 149, 350,\n",
       "       335, 407, 161, 258, 438, 354, 257, 267,  25, 458, 100, 184, 221,\n",
       "       496, 223, 481, 284, 232,  73, 180,  88, 392, 112,  10, 445, 231,\n",
       "       338, 155, 297, 343, 292,  29, 417, 134, 188, 315, 424, 151, 899,\n",
       "       495, 412, 374, 334, 345,  79, 175,  17, 262, 362, 302, 220,   2,\n",
       "       294,   1, 125, 452, 423, 368, 143, 443, 204, 246, 688, 308, 196,\n",
       "       944, 571, 177, 261, 468, 183, 224,  96,  18, 428,  55, 202, 699,\n",
       "       383, 890, 472, 809, 432, 142, 489,  56, 263, 287, 754, 344,  15,\n",
       "       393, 986, 806, 306,  47, 951, 645, 484, 243, 670, 449, 207,  86,\n",
       "       477, 347,  14, 239, 386, 172, 215, 457, 995, 395, 394, 512, 186,\n",
       "       967, 403, 233, 633, 640, 320, 726, 813, 253, 401,   7, 776, 454,\n",
       "        57, 259,  34, 277, 178, 380, 755, 526, 596, 194, 437, 693, 601,\n",
       "       761,  85,  44, 826, 409, 594, 106, 124, 751, 485, 962, 609, 494,\n",
       "       349, 683, 410, 983, 340, 580, 985,  46, 935, 653, 740, 753,  31,\n",
       "       844, 366, 462, 682, 543, 463, 189, 572, 599, 891, 152, 662, 506,\n",
       "       464, 642, 357, 499, 799, 546, 746, 573, 872, 381, 767, 893, 689,\n",
       "        30, 722, 321, 433, 880, 619, 907, 647, 978, 348, 621, 705, 839,\n",
       "       524, 915, 187, 516, 286, 500, 719, 991, 607, 970, 686, 710, 938,\n",
       "       841, 757, 369, 632, 663, 730, 824, 775, 821, 819, 760, 758, 718,\n",
       "       778, 514, 739, 940, 567, 894, 747, 549, 372, 984, 618, 534, 671,\n",
       "       820, 858, 660, 795, 624, 588, 192, 638, 600, 869, 830, 511, 822,\n",
       "       898, 577, 814, 784, 636, 551, 517,  40, 518, 960, 881, 589, 669,\n",
       "       972, 604, 874, 648,  58, 692, 691, 845, 963, 509, 996, 953, 825,\n",
       "       878, 575, 870, 606, 508, 887, 749, 715, 843, 877, 801, 992, 896,\n",
       "       615, 507, 501, 783, 529, 876, 698, 644, 871, 563, 622, 206, 802,\n",
       "       786, 752, 919, 695, 950, 679, 709, 974, 576, 838, 966,  49, 808,\n",
       "       903, 538, 882, 652, 911, 674, 762, 817, 886, 971, 787, 552, 711,\n",
       "       672, 522, 566, 879, 791, 774, 738, 505, 737, 927, 805, 954, 700,\n",
       "       684, 980, 553, 540, 720, 565, 728, 854, 651, 990, 742, 725, 631,\n",
       "       777, 610, 829, 612, 617, 892, 771, 955, 772, 661, 560, 562, 593,\n",
       "       569, 712, 659, 949, 675, 530, 900, 525, 807, 852, 812, 616, 676,\n",
       "       781, 785, 527, 770, 681, 931, 906, 946, 908, 925, 849, 875, 998,\n",
       "       997, 541, 537, 536, 574, 865, 603, 936, 835, 716, 941, 969, 724,\n",
       "       928, 932, 585, 810, 837, 555, 706, 597, 796, 521, 759, 921, 965,\n",
       "       861, 989, 909, 961, 708, 999, 933, 568, 557, 564, 929, 860, 678,\n",
       "       554, 885, 545, 948, 847, 613, 764, 924, 658, 798, 539, 635, 665,\n",
       "       945, 920, 883, 832, 904, 937, 884, 139, 976, 895, 592, 704, 717,\n",
       "       959, 973, 531, 641, 629, 930, 957, 914, 939, 727, 792, 780, 614,\n",
       "       833, 570, 840,  81, 513, 502, 977, 528, 744, 943, 578, 823, 851,\n",
       "       667, 532, 586, 542, 535, 626, 729, 735, 649, 922, 664, 584, 756,\n",
       "       910, 988, 590, 981, 677, 790, 556, 803, 864, 550, 779, 654, 856,\n",
       "       558, 741, 628, 916, 668, 743, 768, 947, 917, 721, 987, 952, 888,\n",
       "       714, 873, 800, 587, 680, 942, 625, 583, 834, 897, 788, 701, 918,\n",
       "       694, 690, 766, 595, 763, 561, 630, 732, 994, 769, 765, 581, 696,\n",
       "       958, 975, 836, 782, 846, 859, 827, 102, 789, 713, 591, 850, 912,\n",
       "       866, 794, 926, 646, 804, 519, 244, 627, 685, 702, 643, 867, 656,\n",
       "       503, 797, 748, 934, 602, 673, 956, 639, 470, 650, 750, 731, 723,\n",
       "       611, 902, 993, 559, 605, 703, 520, 773, 848, 547, 548, 745, 863,\n",
       "       982, 657, 842, 248, 623,  99, 515, 818, 498, 968, 889, 655, 923,\n",
       "       815, 811, 964, 637, 828, 979, 687, 733, 855, 533, 905, 666, 598,\n",
       "       544, 697, 853, 510, 862, 868, 504, 816, 707, 523, 579, 736, 634,\n",
       "       620, 608, 793, 831, 582, 857, 734, 901, 279, 379, 913])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(np.linalg.norm(xhat[vstar] - xhat, axis=1))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce27af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8437bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
